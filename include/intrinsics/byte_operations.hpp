/*
 * Boost Software License - Version 1.0 - August 17th, 2003
 *
 * Permission is hereby granted, free of charge, to any person or organization
 * obtaining a copy of the software and accompanying documentation covered by
 * this license (the "Software") to use, reproduce, display, distribute,
 * execute, and transmit the Software, and to prepare derivative works of the
 * Software, and to permit third-parties to whom the Software is furnished to
 * do so, all subject to the following:
 *
 * The copyright notices in the Software and this entire statement, including
 * the above license grant, this restriction and the following disclaimer,
 * must be included in all copies of the Software, in whole or in part, and
 * all derivative works of the Software, unless such copies or derivative
 * works are solely in the form of machine-executable object code generated by
 * a source language processor.
 *
 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
 * IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
 * FITNESS FOR A PARTICULAR PURPOSE, TITLE AND NON-INFRINGEMENT. IN NO EVENT
 * SHALL THE COPYRIGHT HOLDERS OR ANYONE DISTRIBUTING THE SOFTWARE BE LIABLE
 * FOR ANY DAMAGES OR OTHER LIABILITY, WHETHER IN CONTRACT, TORT OR OTHERWISE,
 * ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER
 * DEALINGS IN THE SOFTWARE.
 */

/**
 * @file byte_operations.hpp
 * @brief Operaciones sobre bytes (bswap, rotl, rotr)
 *
 * Proporciona implementaciones optimizadas de operaciones sobre bytes
 * para todos los compiladores y arquitecturas soportados.
 *
 * @author Julián Calderón Almendros <julian.calderon.almendros@gmail.com>
 * @version 1.0.0
 * @date 2026-01-05
 * @copyright Boost Software License 1.0
 */

#ifndef INTRINSICS_BYTE_OPERATIONS_HPP
#define INTRINSICS_BYTE_OPERATIONS_HPP

#include "compiler_detection.hpp"
#include "fallback_portable.hpp"
#include <cstdint>

namespace intrinsics
{

    // ============================================================================
    // BSWAP - Byte Swap (invertir orden de bytes)
    // ============================================================================

    /**
     * @brief Invierte el orden de los bytes en un uint64_t
     *
     * @param x Valor cuyos bytes se van a intercambiar
     * @return x con bytes en orden inverso
     *
     * Útil para conversiones big-endian ↔ little-endian.
     */
    inline constexpr uint64_t bswap64(uint64_t x) noexcept
    {
#if INTRINSICS_COMPILER_MSVC
        if (INTRINSICS_IS_CONSTANT_EVALUATED())
        {
            return fallback::bswap64_portable(x);
        }
        else
        {
            return _byteswap_uint64(x);
        }
#elif INTRINSICS_COMPILER_INTEL
        // Intel icpx soporta __builtin_bswap64
        return __builtin_bswap64(x);
#elif INTRINSICS_COMPILER_CLANG || INTRINSICS_COMPILER_GCC
        // GCC/Clang: __builtin_bswap64
#if INTRINSICS_ARCH_ARM64 || INTRINSICS_ARCH_ARM32
        // ARM: REV instruction para byte reverse
        return __builtin_bswap64(x);
#elif INTRINSICS_ARCH_RISCV64 || INTRINSICS_ARCH_RISCV32
        // RISC-V: extensión B (Zbb) tiene REV8 para byte reverse
        return __builtin_bswap64(x);
#else
        return __builtin_bswap64(x);
#endif
#else
        // Fallback: C++ puro portable
        return fallback::bswap64_portable(x);
#endif
    }

    /**
     * @brief Bswap para uint32_t
     */
    inline constexpr uint32_t bswap32(uint32_t x) noexcept
    {
#if INTRINSICS_COMPILER_MSVC
        if (INTRINSICS_IS_CONSTANT_EVALUATED())
        {
            return ((x & 0xFF000000) >> 24) | ((x & 0x00FF0000) >> 8) | ((x & 0x0000FF00) << 8) |
                   ((x & 0x000000FF) << 24);
        }
        else
        {
            return _byteswap_ulong(x);
        }
#elif INTRINSICS_COMPILER_INTEL || INTRINSICS_COMPILER_CLANG || INTRINSICS_COMPILER_GCC
        return __builtin_bswap32(x);
#else
        return ((x & 0xFF000000) >> 24) | ((x & 0x00FF0000) >> 8) | ((x & 0x0000FF00) << 8) |
               ((x & 0x000000FF) << 24);
#endif
    }

    /**
     * @brief Bswap para uint16_t
     */
    inline constexpr uint16_t bswap16(uint16_t x) noexcept
    {
#if INTRINSICS_COMPILER_MSVC
        if (INTRINSICS_IS_CONSTANT_EVALUATED())
        {
            return static_cast<uint16_t>((x >> 8) | (x << 8));
        }
        else
        {
            return _byteswap_ushort(x);
        }
#elif INTRINSICS_COMPILER_INTEL || INTRINSICS_COMPILER_CLANG || INTRINSICS_COMPILER_GCC
        return __builtin_bswap16(x);
#else
        return static_cast<uint16_t>((x >> 8) | (x << 8));
#endif
    }

    // ============================================================================
    // ROTL/ROTR - Rotaciones de bits
    // ============================================================================

    /**
     * @brief Rotación a la izquierda de 64 bits
     *
     * @param x Valor a rotar
     * @param s Número de posiciones (0-63)
     * @return x rotado s posiciones a la izquierda
     */
    inline constexpr uint64_t rotl64(uint64_t x, int s) noexcept
    {
        s &= 63; // s %= 64
        if (s == 0)
            return x;

#if INTRINSICS_COMPILER_MSVC
        if (INTRINSICS_IS_CONSTANT_EVALUATED())
        {
            return (x << s) | (x >> (64 - s));
        }
        else
        {
            return _rotl64(x, s);
        }
#elif INTRINSICS_COMPILER_INTEL
// Intel: podría tener _rotl64 también
#if defined(_rotl64)
        return _rotl64(x, s);
#else
        return (x << s) | (x >> (64 - s));
#endif
#elif INTRINSICS_COMPILER_CLANG || INTRINSICS_COMPILER_GCC
        // GCC/Clang: el compilador optimiza esto a ROL instruction
        return (x << s) | (x >> (64 - s));
#else
        return fallback::rotl64_portable(x, s);
#endif
    }

    /**
     * @brief Rotación a la derecha de 64 bits
     *
     * @param x Valor a rotar
     * @param s Número de posiciones (0-63)
     * @return x rotado s posiciones a la derecha
     */
    inline constexpr uint64_t rotr64(uint64_t x, int s) noexcept
    {
        s &= 63; // s %= 64
        if (s == 0)
            return x;

#if INTRINSICS_COMPILER_MSVC
        if (INTRINSICS_IS_CONSTANT_EVALUATED())
        {
            return (x >> s) | (x << (64 - s));
        }
        else
        {
            return _rotr64(x, s);
        }
#elif INTRINSICS_COMPILER_INTEL
// Intel: podría tener _rotr64 también
#if defined(_rotr64)
        return _rotr64(x, s);
#else
        return (x >> s) | (x << (64 - s));
#endif
#elif INTRINSICS_COMPILER_CLANG || INTRINSICS_COMPILER_GCC
        // GCC/Clang: el compilador optimiza esto a ROR instruction
        return (x >> s) | (x << (64 - s));
#else
        return fallback::rotr64_portable(x, s);
#endif
    }

    /**
     * @brief Rotación a la izquierda de 32 bits
     */
    inline constexpr uint32_t rotl32(uint32_t x, int s) noexcept
    {
        s &= 31;
        if (s == 0)
            return x;

#if INTRINSICS_COMPILER_MSVC
        if (INTRINSICS_IS_CONSTANT_EVALUATED())
        {
            return (x << s) | (x >> (32 - s));
        }
        else
        {
            return _rotl(x, s);
        }
#else
        return (x << s) | (x >> (32 - s));
#endif
    }

    /**
     * @brief Rotación a la derecha de 32 bits
     */
    inline constexpr uint32_t rotr32(uint32_t x, int s) noexcept
    {
        s &= 31;
        if (s == 0)
            return x;

#if INTRINSICS_COMPILER_MSVC
        if (INTRINSICS_IS_CONSTANT_EVALUATED())
        {
            return (x >> s) | (x << (32 - s));
        }
        else
        {
            return _rotr(x, s);
        }
#else
        return (x >> s) | (x << (32 - s));
#endif
    }

} // namespace intrinsics

// ============================================================================
// NOTAS DE ARQUITECTURA
// ============================================================================

/**
 * @page byte_ops_arch Notas de Arquitectura para Operaciones de Bytes
 *
 * ## x86-64 (Intel/AMD)
 * - BSWAP: Instruction nativa (486+)
 * - ROL/ROR: Instructions nativas (8086+)
 *
 * ## ARM64 (AArch64)
 * - REV: Byte reverse instruction
 * - ROR: Rotate right instruction
 * - ROL: Simulado como ROR con (32/64 - shift)
 *
 * ## ARM32 (AArch32)
 * - REV: Byte reverse instruction (ARMv6+)
 * - ROR: Rotate right instruction (ARMv4+)
 *
 * ## RISC-V
 * - Extensión B (Zbb): REV8 para byte reverse
 * - Extensión B (Zbb): ROL/ROR instructions
 * - Si no disponible: usar fallback
 *
 * ## PowerPC
 * - ROTLDI/ROTRDI: Rotate left/right doubleword immediate
 * - Byte reverse: Combinar shifts
 *
 * ## Intel Compiler (icpx)
 * - Soporta todos los intrínsecos de MSVC y GCC
 * - Optimizaciones vectoriales para operaciones en bloque
 */

#endif // INTRINSICS_BYTE_OPERATIONS_HPP
